<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | Prab's Code Blog]]></title>
  <link href="http://prabhakar97.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://prabhakar97.github.io/"/>
  <updated>2018-03-29T20:44:09+05:30</updated>
  <id>http://prabhakar97.github.io/</id>
  <author>
    <name><![CDATA[Prabhakar Kumar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Boot Linux From Grub Rescue Prompt]]></title>
    <link href="http://prabhakar97.github.io/blog/2018/01/14/boot-linux-from-grub-rescue-prompt/"/>
    <updated>2018-01-14T20:20:50+05:30</updated>
    <id>http://prabhakar97.github.io/blog/2018/01/14/boot-linux-from-grub-rescue-prompt</id>
    <content type="html"><![CDATA[<p>If you have a dual boot setup of a Linux based OS and Windows 10, and you have setup grub to choose which OS
to boot; you might have experienced the <em>grub rescue prompt</em> which comes up after a Windows 10 update screws up
with the boot files.</p>

<p>Panic not, for it&rsquo;s easy to get back to your beloved Linux distro and fix grub. Here are the steps.</p>

<ul>
<li>Find out the Linux partition (skip, if you already know)

<ul>
<li>Run <code>ls</code> and it should show you a list of partitions like <code>(hd0,msdos1) (hd0,msdos2) ...</code> or in the form <code>(hd0,gpt1), (hd0,gpt2) ...</code></li>
<li>Run ls with the name of the partition followed by a / to see the files on the partition. Like so <code>ls (hd0,gpt1)/</code>. Remember, that forward slash is important. You have to do this for each parition until you find your linux partition - i.e. you see the list of files named <code>dev, proc, usr, etc, mnt</code> etc.</li>
</ul>
</li>
<li>Set the grub modules prefix

<ul>
<li>Run this <code>set prefix=(hd0,msdos3)/boot/grub</code>. This assumes, your Linux partition in previous step was msdos3.</li>
</ul>
</li>
<li>Set the root partition

<ul>
<li>You can set the linux partition as your root partition by running <code>set root=(hd0,msdos3)</code></li>
</ul>
</li>
<li>Load the needed modules

<ul>
<li>We need to load the linux module to be able to boot Linux. Run <code>insmod linux</code> to do that.</li>
</ul>
</li>
<li>Find where your kernel and initramfs are located

<ul>
<li>You can run <code>ls /boot/</code> and it should show a file named <code>vmlinuz-linux</code>. That&rsquo;s your Kernel. At least that&rsquo;s how it is named in Arch Linux and related distros like Antergos and Manjaro. Kernel and Ramdisk have different names on different distros. Centos, Fedora and RHEL have names similar to <code>vmlinuz-3.10.0-693.11.1.el7.x86_64</code> for the Kernel. I assume you are smart enough to figure the naming out.</li>
<li>You can similarly find your initramfs image. Usually it is named something like <code>initramfs-linux.img</code>.</li>
<li>Caveats to look out for when finding the Kernel and initramfs image files - Number one, if the file names are versioned, choose the latest ones. Number two, choose the same version for Kernel and initramfs. And the last and number three, don&rsquo;t choose the names that contain <code>rescue</code> or <code>memtest</code>. They are not the ones we are interested in.</li>
</ul>
</li>
<li>Boot Linux!

<ul>
<li>Having found out the Kernel and Ramdisk images, let&rsquo;s load them up. Run <code>linux /boot/vmlinuz-linux root=/dev/sda3 fb rw quiet</code>. sda3 can probably be hda3 if you have an older machine. And the digit at the end should be same as the root partition number we found in the first step i.e. msdos3 in my case. Now load the Ramdisk by running <code>initrd initramfs-linux.img</code>.</li>
<li>Having loaded &lsquo;em both, let&rsquo;s boot. Run <code>boot</code> and bingo, your system should now boot normally!</li>
</ul>
</li>
<li>Fix grub so that you don&rsquo;t have to go through this ordeal next time

<ul>
<li>Running <code>sudo grub-install /dev/sda</code> or in some cases hda instead of sda, should reinstall grub correctly and fix your booting problems.</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ship a REST API With Node, ES6 and MongoDB - Part 1]]></title>
    <link href="http://prabhakar97.github.io/blog/2017/03/22/bootstrap-a-restful-api-app-with-node-es6-mongo-linux/"/>
    <updated>2017-03-22T21:52:40+05:30</updated>
    <id>http://prabhakar97.github.io/blog/2017/03/22/bootstrap-a-restful-api-app-with-node-es6-mongo-linux</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>NodeJS has been gaining a lot of traction recently, especially for web applications. Lots of new web applications
are now being built with tools from  the Node ecosystem. A possible reason is the umpteen number of javascript
developers out in the wild. Other one is  the blazing speed of
<a href="https://en.wikipedia.org/wiki/V8_(JavaScript_engine">V8 engine</a>). Heck, even shiny desktop apps are now being built
with Node viz. Popcorn Time.</p>

<p>In this post I will walk through everything I did to ship an API app. Ship as in - ready to serve production traffic.</p>

<h3>About the stack</h3>

<p>We will be using <a href="https://expressjs.com/">Express</a> as our web app framework. Express is minimalistic, fast and quietly
gets out of our way when you want to detour through the dirt road. It is unlike convention over configuration style in
<a href="http://rubyonrails.org/">Rails</a> and <a href="https://playframework.com/">Play framework</a> where you are good as long as you
follow the conventions recommended by the framework. Going gets tough, if you start deviating. There are frameworks
built specifically for facilitating API building. An example would be <a href="http://restify.com/">Restify</a>. The reason of
not choosing such a framework for this exercise is to understand the intricacies of building an API. Restify would
shield us from understanding lots of stuff.</p>

<p>Also, we wil be writing our javascript in <a href="http://es6-features.org/">ES6</a> which is cleaner and hands down a better
language than the javascript specced in ES5. Latest version of node still doesn&rsquo;t fully support ES6, so we will use a
transpiler named <a href="http://babeljs.io/">Babel</a> which transpiles code written by us into code conforming to ES5 for which
node has full support. In the future when node catches up, we can turn off transpilation and run our ES6 code directly
with node.</p>

<p><a href="https://www.mongodb.com/">MongoDB</a> will be our database. It is a document oriented NoSQL database. What that means
is - it is unlike the RDBMSes like MySQL or Oracle which let you model the world by defining a schema in form
of tables recording their properties and then linking them with primary and foreign keys. With MongoDB we model our
worldly entities in form of documents which are similar to JSON objects . The biggest advantage of NoSQL databases like
MongoDB is that they are designed to be horizontally scalable - whenever we need to increase performance, we just
add few more machines to the DB cluster and the database engine takes care of redistributing data and query traffic
across all available machines. RDBMSes are limited by theory, in terms of horizontal scalability. A discussion of this
is beyond the scope of this article, but if you are interested in knowing more about it you can browse the interwebs
for this nuisance called CAP theorem.</p>

<h3>About the project</h3>

<p>We are going to build an API which can power a web application and/or a mobile app. The app is a social code snippet
sharing system where the users can share frequently encountered code snippets that are used in a developer&rsquo;s day to
day life for solving mundane problems which they are too lazy to code themselves. Usually, as developers we google for
our problem, find link to a stackoverflow question and copy the snippet from there and use from. In our case we let
the users share the snippet, enter a description, select the language, optionally add some tags and publish it. A user
can also thumb up a snippet or mark it as junk. We also allow some experienced users to edit the snippets and/or
descriptions for clarity. We define experience with a formula derived from number of upvotes to their questions by
other users, their age on the site and their time spent on the site. Also, we do away with logins through passwords.
We provide OAuth based logins through Google, Facebook, Twitter etc. Apart from these functional features, we will
also do some non-functional stuff like generate an SEO friendly URL for each snippet so that Googlebot can find our
snippets and list in search results. Let&rsquo;s wear the product manager hat for a moment and write down the high level
product requirements for our application.</p>

<h4>As a guest user I should be able to</h4>

<ul>
<li>search for snipppets through description and/or code matches</li>
<li>list snippets by language, and sort them by

<ul>
<li>most voted</li>
<li>most viewed</li>
</ul>
</li>
<li>login using Google, Facebook or Twitter auth</li>
</ul>


<h4>As a logged-in user I should be able to</h4>

<ul>
<li>perform snippet operations

<ul>
<li>post a snippet</li>
<li>edit my posted snippets</li>
<li>view a snippet and see all previous versions of a snippet, if they have been edited</li>
</ul>
</li>
<li>perform profile operations

<ul>
<li>view my profile</li>
<li>refresh upstream information in the profile</li>
<li>view others' profiles</li>
<li>view activity of a user, like snippets posted, snippets upvoted, snippets edited etc.</li>
</ul>
</li>
<li>perform friendship operations

<ul>
<li>send friend requests to people</li>
<li>accept/reject others' friend requests</li>
<li>ignore/block a user</li>
</ul>
</li>
<li>perform feed operations

<ul>
<li>view a feed which shows my friends' activity on the website</li>
<li>like and comment on activities in the feed</li>
</ul>
</li>
<li>perform leaderboard operations

<ul>
<li>view leaderboard of snippets</li>
<li>view leaderboard of users</li>
<li>filter leaderboard by language, user location etc.</li>
</ul>
</li>
<li>perform messaging operations

<ul>
<li>send private messages to my friends</li>
<li>send private messages to non-friends</li>
<li>view my inbox, categorized with messages from friends/non-friends</li>
</ul>
</li>
</ul>


<h3>Why API?</h3>

<p>Let&rsquo;s take a step back and understand why should we write an API? Why not a simple MVC web application? APIs are great
for scaling, technically as well as logistically. With an API, we define a set of operations, which cover all the
interactions of users and other systems with our application. Then we write client apps, which talk to the API and get
the job done. So, next time you swipe left in gmail to archive an email, you should know that an API call has been
made by the GMail app residing on your phone, to the GMail servers along with some parameters which did the actual
archiving of the email.</p>

<p>What is logistic stability? Ok, I just made up this term! With an API as contract in place, the client app can
independently scale with the actual functional implementation. We can have different people (or teams) working on the
different client apps. As long as they have the API spec they can work independently. Also, the same API can power a
native iOS app, an Android app, a mobile website and a web application. These client apps make API calls to fetch and
display relevant data and perform operations upon user interactions.</p>

<p>In terms of technical scalability, the people working on the backend can independently scale the most used operations
in the API. For instance, if we are getting millions of calls for our compute intensive <code>findBugs</code> operation in a
day, we can intelligently increase the resources it needs. One way would be to have a dedicated independent machine of
high configuration just for this operation in the API. And we leverage the power of distributed systems and horizontal
scalability! We will get into the details of this when we talk about shipping once we are code complete.</p>

<h2>Dev Env setup</h2>

<p>Before we design our data model, let&rsquo;s get our hands dirty a bit, write a hello world app with Express and get MongoDB
setup on our workstation.</p>

<p>I am an <a href="https://www.archlinux.org/">Arch Linux</a> devotee. The instructions here should work perfectly on Arch. The
onus of changing the commands to suit your package manager(apt, yum, emerge, brew) is upto you.</p>

<h3>Install node, npm and mongodb</h3>

<p>The following commands will install <code>node</code>, <code>npm</code> and <code>mongodb</code> for us. <code>node</code> is the javascript runtime executable
which is actually going to run our code. <code>npm</code> is the package manager which takes care of resolving dependencies on
third party libraries, downloading them and setting up their paths correctly so that we have a lot of pre-written
code in form of modules available at our disposal.</p>

<p>Mongodb will also be started and enabled for autostart. If you don&rsquo;t want it to be auto started everytime you boot,
don&rsquo;t execute the last command.</p>

<pre><code class="sh">sudo pacman -Syu node npm mongodb

sudo systemctl start mongodb

sudo systemctl enable mongodb
</code></pre>

<p>As of this writing, I got node 7.2, npm 4.0 and mongodb 3.2. The javascript ecosystem is a very fast moving one. Some
of the code mentioned hereon might get obsolete in a couple of years but the general idea remains the same.</p>

<h3>Setup the initial package.json</h3>

<p>In the node world <code>package.json</code> is the file which contains the details of our dependencies and run configurations.
In Rails world, it is analogous to <code>Gemfile</code> but on steroids. In java world it is kind of analogous to <code>build.gradle</code>
or a <code>pom.xml</code>.</p>

<pre><code class="sh">mkdir -p ~/Documents/Projects/js-snipcode
cd !$
npm init
</code></pre>

<p> The second command might seem unfamiliar. !$ represents the last paramter of previous command in bash and zsh. So it
will just take you to the newly created directory from the previous step.</p>

<p>The <code>npm init</code> is interactive and it will first ask you for a project name. Then configure the version and description.
Next it asks for the entry point for the app. You can leave it as <code>index.js</code>. Keep pressing enter to accept the
defaults for other fields or change if you like. For now we ignore the test command. A <code>package.json</code> file will be
created in the end.</p>

<h3>Install Express</h3>

<p>Express is the web framework library that we are going to use. Now let&rsquo;s add a dependency on Express, add babel
transpilation of ES6 and get from zero to &ldquo;Hello World!&rdquo;.</p>

<pre><code class="sh">npm install express --save
npm install --save-dev babel-cli babel-preset-latest
</code></pre>

<p>Running the above commands will download Express, babel-cli and babel&rsquo;s latest preset. <code>--save</code> flag makes an entry in
the <code>dependencies</code> section of package.json. Guess what does the <code>--save-dev</code> flag do? You got it right! It makes an
entry in <code>devDependencies</code> in <code>package.json</code>. Dev dependencies are different from dependencies in that they
are not required for running the app. They are only used during development, for instance for transpilation during
build. Let&rsquo;s also add two target scripts named <code>build</code> and <code>start</code> in the <code>package.json</code>. Running <code>npm run build</code> will
tell babel to transpile everything in <code>src</code> directory recursively and output the transpiled files in <code>dist</code> directory.
<code>npm run start</code> in the root directory of our project will start our web server by running the command
<code>node dist/index.js</code>. Also, don&rsquo;t forget <code>mkdir src; mv index.js src</code>. Here&rsquo;s the updated <code>package.json</code>.</p>

<pre><code class="json package.json">{
  "name": "js-snipcode",
  "version": "1.0.0",
  "description": "API in NodeJS for the Snipcode project.",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1",
    "build": "babel src -d dist --presets latest",
    "start": "node dist/index.js"
  },
  "author": "Prabhakar Kumar",
  "license": "ISC",
  "dependencies": {
    "express": "^4.14.0"
  },
  "devDependencies": {
    "babel-cli": "^6.18.0",
    "babel-preset-latest": "^6.18.0"
  }
}
</code></pre>

<h3>Zero to Hello World!</h3>

<p>Let&rsquo;s edit our <code>src/index.js</code> and write relevant code to make a Hello World app.</p>

<pre><code class="javascript index.js">import express from 'express';

const app = express();

app.get('/', (req, res) =&gt;
  res.send('Hello World!')
);

app.listen(3000, () =&gt; 
  console.log('Server is up on port 3000!')
);
</code></pre>

<p>Now let&rsquo;s build and run.</p>

<pre><code class="sh">npm run build
npm run start
</code></pre>

<p>If everything went well as we discussed, you will see a message on the console that says server is up on port 3000.
Now if you fire up firefox or chromium and go to <a href="http://localhost:3000">localhost:3000</a>, you will see the evergreen
&lsquo;Hello world!&rsquo; message staring at you on a white screen.</p>

<p>Before we start writing more code, I&rsquo;ll explain the meaning of the lines in our Hello World web app. But, before that
let&rsquo;s pivot and focus on learning our database and design a basic data model.</p>

<h3>Play with mongo console</h3>

<p>Let&rsquo;s play with mongo console a bit to gain some familiarity with it.</p>

<pre><code class="text">$ mongo
MongoDB shell version: 3.2.10
connecting to: test
Welcome to the MongoDB shell.
For interactive help, type "help".
For more comprehensive documentation, see
        http://docs.mongodb.org/
Questions? Try the support group
        http://groups.google.com/group/mongodb-user
Server has startup warnings:
2016-12-04T07:40:24.545-0500 I CONTROL  [initandlisten]
2016-12-04T07:40:24.545-0500 I CONTROL  [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.
2016-12-04T07:40:24.545-0500 I CONTROL  [initandlisten] **        We suggest setting it to 'never'
2016-12-04T07:40:24.545-0500 I CONTROL  [initandlisten]
&gt; show databases
local  0.000GB
&gt; use snipcode
switched to db snipcode
&gt; db.users.insert({name: "John Doe", country: "United States", "sex": 'M', dob: ISODate('1970-01-01')})
WriteResult({ "nInserted" : 1 })
&gt; db.users.find()
{ "_id" : ObjectId("58441a27d01af6e5b1ae6f74"), "name" : "John Doe", "country" : "United States", "sex" : "M", "dob" : ISODate("1970-01-01T00:00:00Z") ers.insert({name: "Jane Doe", country: "United States", "sex": 'F', dob: ISODate('1970-01-01')})
WriteResult({ "nInserted" : 1 })
&gt; db.users.find()
{ "_id" : ObjectId("58441a27d01af6e5b1ae6f74"), "name" : "John Doe", "country" : "United States", "sex" : "M", "dob" : ISODate("1970-01-01T00:00:00Z") }
{ "_id" : ObjectId("58441a5bd01af6e5b1ae6f75"), "name" : "Jane Doe", "country" : "United States", "sex" : "F", "dob" : ISODate("1970-01-01T00:00:00Z") }
&gt; db.users.find({sex: 'F'})
{ "_id" : ObjectId("58441a5bd01af6e5b1ae6f75"), "name" : "Jane Doe", "country" : "United States", "sex" : "F", "dob" : ISODate("1970-01-01T00:00:00Z") }
</code></pre>

<p>Similar to MySQL and friends (MariaDB, Aurora), Mongodb organizes it&rsquo;s data in databases. We don&rsquo;t need to explicitly
create a database unlike MySQL. It gets created as soon as we try to write something to it. Inside a Mongodb database,
the database is organized in collections. A collection is analogous to tables in RDBMS, and more flexible. A
collection doesn&rsquo;t have a fixed schema. So, one document (record/row in RDBMS) can have fields different from others
in the same collection. In the above example, we switched to database named <code>snipcode</code>. Then we inserted a document
describing a user named &lsquo;John Doe&rsquo;. Upon doing a <code>find()</code> (which is analogous to SQL&rsquo;s SELECT) on that collection we
got the record, along with a unique record ID called ObjectID. Then we inserted another record for <code>Jane Doe</code>. Then we
ran a query which returns all female users. For this, we provided the query condition <code>sex: 'F'</code> which is similar to
WHERE sex = &lsquo;F&rsquo; in SQL.</p>

<p>As of now, this much familiarity is enough for us to get started. We will dive deeper as and when we need.</p>

<h2>Next part</h2>

<p>In this part we got bootstrapped and got our hands dirty. In the next part we will start with data modeling and
continue further. Stay tuned for it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compile Goaccess From Source on CentOS 7]]></title>
    <link href="http://prabhakar97.github.io/blog/2016/07/08/compile-goaccess-from-source-on-centos-7/"/>
    <updated>2016-07-08T07:30:32+05:30</updated>
    <id>http://prabhakar97.github.io/blog/2016/07/08/compile-goaccess-from-source-on-centos-7</id>
    <content type="html"><![CDATA[<p><a href="https://goaccess.io">Goaccess</a> is a neat little utility which scans through your web server (I use nginx) logs and generates a nice HTML report of
your site&rsquo;s access statistics. Here is a <a href="http://rt.goaccess.io">sample from their site</a>. I run CentOS 7 on an EC2 Instance where I run a pet project. I wanted a light web analyzer that just works. I have
<a href="https://fedoraproject.org/wiki/EPEL">epel</a> enabled on my instance so I just installed goaccess by <code>sudo yum install goaccess</code>. It worked and I was able
to see some stats. But then I figured out that the version from repositories is quite an old one at 0.9.8. The latest one is 1.0.2 from the website.
So, I just uninstalled it <code>sudo yum remove goaccess</code>.</p>

<p>I downloaded the source tarball and after a few hiccups I was able to get it running. There are two quirks you need to watch out for. First one is
that, enabling geoip in goaccess requires installation of maxmind&rsquo;s geoip database. The installed database from yum is very small, so you need to
update it and change symlink /usr/share/GeoIP/GeoIP.dat to point to /usr/share/GeoIP/GeoLiteCountry.dat. Second quirk is that by default the configure
script doesn&rsquo;t figure out the geoip devel libs path so you need to manually point to it while configuring.</p>

<pre><code class="sh">sudo yum install GeoIP
geoipupdate
sudo rm /usr/share/GeoIP.dat
sudo ln -s /usr/share/{GeoLiteCountry,GeoIP}.dat 

wget http://tar.goaccess.io/goaccess-1.0.2.tar.gz
tar -xzvf goaccess-1.0.2.tar.gz
cd goaccess-1.0.2
LD_FLAGS='-L/usr/lib64/' ./configure --enable-utf8 --enable-geoip
make
sudo make install
</code></pre>

<p>I also created a daily crontab entry to generate reports daily and put it in my <code>public</code> folder of rails directory, all the files in which I serve
statically from nginx. So I can just type <a href="http://mydomain.com/access.html">http://mydomain.com/access.html</a> and see the reports. Here is my crontab entry.</p>

<pre><code class="sh crontab">@daily /bin/zcat -f /var/log/nginx/access.log* | /usr/local/bin/goaccess -a -o /home/ec2-user/my_rails_dir/public/access.html
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Find Below]]></title>
    <link href="http://prabhakar97.github.io/blog/2015/04/21/find-below/"/>
    <updated>2015-04-21T03:22:00+05:30</updated>
    <id>http://prabhakar97.github.io/blog/2015/04/21/find-below</id>
    <content type="html"><![CDATA[<p>This is a small piece of snippet that can go into your <code>.zshrc</code> and make your life easier sometimes. This whips up a new command named <code>findbelow</code> for you. This command takes as argument, a string and returns all the files below your current directory whose names contain the entered string as a substring.</p>

<pre><code class="sh findbelow">findbelow () {
  find ./ -regex ".*/$1.*"
}
</code></pre>

<h3>Bonus</h3>

<p>The below piece of snippet enables you to jump n directories upwards from your current <code>pwd</code> by typing <code>u n</code>. For example: <code>u 5</code> will take you 5 directories up from your current position.
<code>sh u
u () {
  set -A ud
  ud[1+${1-1}]=
  cd ${(j:../:)ud}
}
</code>
This has been tested on zsh.</p>
]]></content>
  </entry>
  
</feed>
